#!/usr/bin/env python
# coding: utf-8
###########Library Load##########
import pandas as pd
import numpy as np
import pickle
import zipfile
import argparse
import streamlit as st
import warnings
from sklearn.preprocessing import MinMaxScaler
from seq2seq import Seq2Seq
from functions import most_similar_weight,calculate_bmr,calculate_daily_calories,calculate_daily_nutrient_intake
from postprocessing import make_result
from metrics import ap_at_k
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
###########Argparser#############
parser = argparse.ArgumentParser()
parser.add_argument('--weights_path',type=str, default='configuration/model_weights.ckpt')
args = parser.parse_args()
warnings.filterwarnings("ignore")
############Data load#############
@st.cache_data
def load_data():
    complete_df = pd.read_csv('complete_df.csv')
    return complete_df
@st.cache_data
def load_dedup():
    dedup_df = pd.read_csv('dedup_df.csv')
    return dedup_df
# íŒŒì¼ì—ì„œ ë”•ì…”ë„ˆë¦¬ ë¡œë“œ
@st.cache_data
def load_workout_type():
    with open('workout_ability.pkl', 'rb') as file:
        workout_type = pickle.load(file)
    return workout_type
@st.cache_data
def load_detail_ex():
    workout_df = pd.read_csv('workout.csv')
    return workout_df
def load_TOKENIZER():
    with open('configuration/tokenizer2.pkl', 'rb') as file:
        TOKENIZER = pickle.load(file)
    return TOKENIZER
############Functions#############
def set_model():
    my_model = Seq2Seq(256, 713, 100, 76, 2, 3)
    if args.weights_path:
        my_model.load_weights(args.weights_path)
    return  my_model
def extract_seq(my_model,TOKENIZER,INPUT_LEN,first_seq):
    init = make_result(my_model, TOKENIZER, INPUT_LEN)
    infered_seq = init.make_seq(first_seq)
    return infered_seq
def filter_ex_type(type):
    work_type = pd.DataFrame(type).fillna(0)
    workout_after = pd.concat([work_type,work_type],axis=0).reset_index(drop=True)
    return workout_after
def con_ex_info(df1,df2):
    add_info = pd.merge(df1['1ìˆœìœ„'],df2,how='left',left_on='1ìˆœìœ„',right_on='trng_nm')
    add_info2 = add_info.drop_duplicates(subset='1ìˆœìœ„').drop(['trng_nm','trng_aim_nm'],axis=1)
    add_info2.columns = ['1ìˆœìœ„','ë°œë‹¬ëŠ¥ë ¥','ìš´ë™ë¶€ìœ„','ì¤€ë¹„ë¬¼']
    add_info2['ë°œë‹¬ëŠ¥ë ¥'].fillna('-',inplace=True)
    add_info2['ìš´ë™ë¶€ìœ„'].fillna('ì „ì‹ ',inplace=True)
    add_info2['ì¤€ë¹„ë¬¼'].fillna('ì—†ìŒ',inplace=True)
    return add_info2
def get_url(workout_name:str):
    user_agent= '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36'
    # ì›¹ë“œë¼ì´ë²„ option ì„¤ì • (ìƒë½ê°€ëŠ¥)
    options = webdriver.ChromeOptions()
    options.add_argument('--ignore-certificate-errors')
    options.add_argument(user_agent)
    options.add_argument('--headless') 
    # ì›¹ë“œë¼ì´ë²„ ì„¤ì •
    # driver = webdriver.Chrome('/path/to/chromedriver')
    driver = webdriver.Chrome(options=options)
    # ìœ íŠœë¸Œ ì ‘ì†
    driver.get('https://www.youtube.com')

    # ìœ íŠœë¸Œ ê²€ìƒ‰ì°½ì— í‚¤ì›Œë“œ ì…ë ¥
    search_box = driver.find_element(By.XPATH, '//input[@id="search"]')
    search_box.send_keys(f"ì²´ë ¥100 {workout_name}")
    # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­
    search_button = driver.find_element(By.XPATH, '//button[@id="search-icon-legacy"]')
    search_button.click()
    # ìƒìœ„ ë™ì˜ìƒ ì°¾ê¸°
    first_video = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'a#video-title')))
    # ì²« ë²ˆì§¸ ë™ì˜ìƒ í´ë¦­
    first_video.click()
    video_url = driver.current_url
    # ë¸Œë¼ìš°ì € ë‹«ê¸°
    #driver.quit()
    return video_url
def make_warmup_df(recomm_first,proba):
    recomm_delete = [v[:-1] if len(v)>1 else v for v in recomm_first]
    probability = [x for x in np.round(proba / np.sum(proba)*100,2)]
    workout=pd.DataFrame(recomm_delete)
    workout2 = pd.concat([pd.DataFrame(probability),workout],axis=1)
    workout2.index=['1ìˆœìœ„','2ìˆœìœ„','3ìˆœìœ„','4ìˆœìœ„','5ìˆœìœ„']
    workout2.columns=[['rating(%)']+[str(x)+'stìš´ë™' for x in range(1,len(workout2.columns))]][0]
    workout2.fillna('ì—†ìŒ',inplace=True)
    workout2['select'] = [False for _ in range(len(workout2))]
    return workout2
def make_main_df(all_seq,detail_workout):
    result = list(dict.fromkeys(all_seq))
    after_recomm = pd.DataFrame(result).fillna('ì—†ìŒ')
    after_recomm.columns=['1ìˆœìœ„']
    after_recomm.index=[str(x)+'stìš´ë™' for x in range(1,len(after_recomm)+1)]
    detailed_ex = con_ex_info(after_recomm,detail_workout)
    detailed_ex.dropna(axis=0,inplace=True)
    detailed_ex['select'] = [False for _ in range(len(detailed_ex))]
    detailed_ex.index = [str(x)+'stìš´ë™' for x in range(1,len(detailed_ex)+1)]
    return detailed_ex
def cosine_similarity(a, b):
    dot_product = np.dot(a, b)
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    similarity = dot_product / (norm_a * norm_b)
    return similarity
# ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜
def euclidean_distance(a, b):
    return np.linalg.norm(a - b)
def most_similar_weight_for_None(profile,df,k):
    mm=MinMaxScaler()
    df_re = df.copy()
    bmi = profile[2] / pow(profile[1],2)
    abi= profile[0]*bmi
    all = profile+[bmi]+[abi]
    euclidean_distances = 1 / df_re.iloc[:,:6].apply(lambda row: euclidean_distance(all, np.array(row)), axis=1)
    sim_scaled= (mm.fit_transform(euclidean_distances.values.reshape(-1,1))).reshape(1,-1)
    df_re['dist'] = sim_scaled[0]
    df_re = df_re.dropna().sort_values('dist',ascending=False)
    closest_indices = df_re['first_p_first'].values.tolist()[:k]
    proba = df_re['dist'].values.tolist()[:k]
    return closest_indices, proba
def most_similar_weight(profile,purpose,df,profile_w,candidate_w,k):
    mm= MinMaxScaler()
    df_re=df.copy()
    bmi = profile[2] / pow(profile[1],2)
    abi= profile[0]*bmi
    all = profile+[bmi]+[abi]
    up_idx = [['ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥','ì‹¬íì§€êµ¬ë ¥','ë¯¼ì²©ì„±/ìˆœë°œë ¥','ìœ ì—°ì„±','í‰í˜•ì„±','í˜‘ì‘ë ¥'].index(x) for x in purpose]
    cadidates= [0,0,0,0,0,0]
    for v in up_idx:
        cadidates[v]=1
    # ê° í–‰ì˜ ë²¡í„°ì™€ ì£¼ì–´ì§„ ë²¡í„° ì‚¬ì´ì˜ ìœ ì‚¬ë„ì™€ ê±°ë¦¬ ê³„ì‚°
    cosine_similarities = df_re[['ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥','ì‹¬íì§€êµ¬ë ¥','ë¯¼ì²©ì„±/ìˆœë°œë ¥','ìœ ì—°ì„±','í‰í˜•ì„±','í˜‘ì‘ë ¥']].apply(lambda row: cosine_similarity(cadidates, np.array(row)), axis=1)
    euclidean_distances = 1 / df_re[['age','height','weight','BMI','age*bmi','sex']].apply(lambda row: euclidean_distance(all, np.array(row)), axis=1)
    sim_scaled = (mm.fit_transform(euclidean_distances.values.reshape(-1,1))*profile_w).reshape(1,-1)+cosine_similarities.values*candidate_w
    df_re['dist'] = sim_scaled[0]
    df_re = df_re.dropna().sort_values('dist',ascending=False)
    closest_indices = df_re['first_p_first'].values.tolist()[:k]
    proba = df_re['dist'].values.tolist()[:k]
    return closest_indices, proba

def dedup_list(list):
    # ê° ë¬¸ìì—´ì˜ ê²‰ì— ìˆëŠ” ì‘ì€ ë”°ì˜´í‘œ ì œê±°
    data = [x.strip("[]").replace("'", "") for x in list]
    # ë¦¬ìŠ¤íŠ¸ ë‚´ì˜ ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¨ì¼ ë¦¬ìŠ¤íŠ¸ë¡œ í’€ê¸°
    result = [x.split(", ") if ", " in x else [x] for x in data]
    return result
def longterm_routine(day,age,height,weight,gender,df,my_model,tokenizer,detail_workout):
    long_df = pd.DataFrame()
    recomm_first,_= most_similar_weight_for_None([age,height,weight,gender],df,day)
    for day in range(0,day):
        all_seq = extract_seq(my_model,tokenizer,26,recomm_first[day])
        daily_routine = pd.DataFrame(all_seq)
        daily_routine['ì¼ì°¨']=f'{day+1}ì¼ì°¨'
        long_df = pd.concat([long_df,daily_routine],axis=0)
    long_df_add = pd.merge(long_df,detail_workout,how='left',left_on=0,right_on='trng_nm').drop_duplicates(subset='trng_nm')
    long_df_add.set_index('ì¼ì°¨',inplace=True)
    long_df_add.drop(['trng_nm','trng_aim_nm'],axis=1,inplace=True)
    long_df_add['ftns_fctr_nm'].fillna('-',inplace=True)
    long_df_add['trng_part_nm'].fillna('ì „ì‹ ',inplace=True)
    long_df_add['tool_nm'].fillna('ì—†ìŒ',inplace=True)
    long_df_add.columns=['ìš´ë™ì´ë¦„','ë°œë‹¬ëŠ¥ë ¥','ìš´ë™ë¶€ìœ„','ì¤€ë¹„ë¬¼']
    return long_df_add
###########Initialize#############
set_page = st.set_page_config(
    page_title="Workout Routine Recommendations",
    page_icon="ğŸ’ª",
    layout="wide",
)
# Store the initial value of widgets in session state
if "start_btn" not in st.session_state:
    st.session_state.start_btn = False
###########Load Configuration###########
complete_df = load_data()
complete_df['first_p_first'] = dedup_list(complete_df['first_p_first'])
dedup_df = load_dedup()
dedup_df.set_index('Unnamed: 0',inplace=True)
workout_type= load_workout_type()
workout_after = filter_ex_type(workout_type)
detail_workout=load_detail_ex()  
TOKENIZER=load_TOKENIZER()
my_model= set_model()
##############Side bar#############
def main():  
    st.sidebar.title('Configuration')
    st.sidebar.subheader('ë§ì¶¤í˜• ìš´ë™ ë£¨í‹´ ì¶”ì²œì„ ìœ„í•œ ì˜µì…˜',divider='red')
    age = st.sidebar.number_input("ğŸ™‹ğŸ»ë‚˜ì´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",  value=20,min_value=7, max_value=100)
    height = st.sidebar.number_input("ğŸƒí‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",  value=170,min_value=140,max_value=350)
    weight = st.sidebar.number_input("ğŸ¦¶ëª¸ë¬´ê²Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.",  value=50,min_value=30,max_value=300)
    sex =st.sidebar.radio(
        "â™‚ï¸â™€ï¸ì„±ë³„ì„ ê³ ë¥´ì„¸ìš”.",
        ['ë‚¨ì','ì—¬ì'],
        horizontal=True
        )
    if sex=='ë‚¨ì':
        gender = 1
    elif sex=='ì—¬ì':
        gender=0
    purpose =st.sidebar.multiselect(
        "ğŸ‚ìš´ë™ ëª©í‘œì„ ê³ ë¥´ì„¸ìš”",
        ['ì—†ìŒ','ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥','ì‹¬íì§€êµ¬ë ¥','ë¯¼ì²©ì„±/ìˆœë°œë ¥','ìœ ì—°ì„±','í‰í˜•ì„±','í˜‘ì‘ë ¥'],
        )

    activity =st.sidebar.radio(
        "ğŸŠí™œë™ ìˆ˜ì¤€ì„ ê³ ë¥´ì„¸ìš”.",
        ['ì§‘ì—ë§Œ ìˆìŒ','ì•½ê°„ í™œë™ì ','ì ë‹¹íˆ í™œë™ì ','ë§¤ìš° í™œë™ì '],
        horizontal=True
        )
    updown =st.sidebar.radio(
        "ğŸ‹ï¸â€â™€ï¸í¬ë§ ì²´ì¤‘ì„ ê³ ë¥´ì„¸ìš”.",
        ['ì²´ì¤‘ ê°ì†Œ','ì²´ì¤‘ ìœ ì§€','ì²´ì¤‘ ì¦ê°€'],
        horizontal=True
        )
    long_recomm =st.sidebar.radio(
        "ğŸ¤¾ğŸ»â€â™‚ï¸ìš´ë™ ë£¨í‹´ ì¶”ì²œ ê¸°ê°„ì„ ê³ ë¥´ì„¸ìš”.",
        ['3ì¼','7ì¼','14ì¼'],
        horizontal=True
        )
    st.sidebar.subheader('ìš´ë™ì˜ìƒ ê²€ìƒ‰',divider='red')
    workout_name = st.sidebar.text_input(
                "ğŸ¯ìš´ë™ì´ë¦„ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš” ğŸ‘‡",
                label_visibility="visible",
                disabled=False,
                placeholder='ì¤„ë„˜ê¸°..ë™ì  ìŠ¤íŠ¸ë ˆì¹­..',
                )
    ################Body##################
    st.title('Workout Routine Recommendation')
    s_col1,s_col2,s_col3,s_col4,s_col5 = st.columns([1,1,1,1,1])
    with s_col1:
        bmr = calculate_bmr(gender, age, height, weight)
        st.metric(label='ê¸°ì´ˆ ëŒ€ì‚¬ëŸ‰(BMR): ', value=f'{bmr} kcal')
    with s_col2:
        daily_cal = calculate_daily_calories(bmr, activity)
        st.metric(label='í•˜ë£¨ ê¶Œì¥ ì¹¼ë¡œë¦¬ ì„­ì·¨ëŸ‰(TTE): ', value=f'{daily_cal} kcal')
    with s_col3:
        neutrinuts = calculate_daily_nutrient_intake(daily_cal,updown)
        st.metric(label='í•˜ë£¨ ì ì • íƒ„ìˆ˜í™”ë¬¼ ì„­ì·¨ëŸ‰: ', value=f'{np.round(neutrinuts[0],3)} g')
    with s_col4:
        st.metric(label='í•˜ë£¨ ì ì • ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰: ', value=f'{np.round(neutrinuts[1],3)} g')
    with s_col5:
        st.metric(label='í•˜ë£¨ ì ì • ì§€ë°© ì„­ì·¨ëŸ‰: ', value=f'{np.round(neutrinuts[2],3)} g')
    with st.container():
        con_df = pd.concat([complete_df.iloc[:,:9],workout_after],axis=1)
        new_criteria= con_df.loc[dedup_df.index]
        activity_des = st.expander('BMR,TTE,ì˜ì–‘ì†Œ ê³„ì‚° ë°©ì‹ì— ëŒ€í•œ ì„¤ëª…ì„ ë³´ë ¤ë©´ ğŸ‘‰')
        with activity_des:
             with st.container():
                 st.write('â— ê¸°ì´ˆëŒ€ì‚¬ëŸ‰(Basal Metabolic Rate, BMR)ì€ ì•ˆì •ëœ ìƒíƒœì—ì„œ ìµœì†Œí•œì˜ ì—ë„ˆì§€ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì—ë„ˆì§€ ì–‘ì„ ë§í•©ë‹ˆë‹¤. ì‰½ê²Œ ë§í•´, ëª¸ì´ ì•ˆì •ëœ ìƒíƒœì—ì„œë„ ê¸°ëŠ¥ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ìµœì†Œí•œì˜ ì¹¼ë¡œë¦¬ ì†Œë¹„ëŸ‰ì…ë‹ˆë‹¤. í˜¸í¡, í˜ˆì•¡ìˆœí™˜, ì²´ì˜¨ ì¡°ì ˆ ë“±ì˜ ê¸°ì´ˆì ì¸ ìƒë¦¬ ì‘ìš©ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ì—ë„ˆì§€ ì–‘ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.í•´ë¦¬ìŠ¤-ë² ë„¤ë”•íŠ¸ ê³µì‹ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.')
                 st.write('â— Total Energy Expenditure(TTE)ëŠ” ì¼ì¼ ì´ ì—ë„ˆì§€ ì†Œë¹„ëŸ‰ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ìš°ë¦¬ê°€ í•˜ë£¨ ë™ì•ˆ ì†Œë¹„í•˜ëŠ” ì´ ì¹¼ë¡œë¦¬ ì–‘ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. TTEëŠ” ê¸°ì´ˆëŒ€ì‚¬ëŸ‰(BMR, Basal Metabolic Rate)ê³¼ ì‹ ì²´í™œë™ì— ì˜í•œ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ í¬í•¨í•œ ê°’ìœ¼ë¡œ, BMRì— í™œë™ ìˆ˜ì¤€ì„ ê³±í•˜ì—¬ ê³„ì‚°ë©ë‹ˆë‹¤.')
                 st.write('â— ì˜ì–‘ì†Œ ì„­ì·¨ëŸ‰ì€ ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤, êµ­ë¯¼ê±´ê°•ì˜ì–‘ì¡°ì‚¬ ìë£Œ í†µí•´ ì‚¬ë§ë¥  ë‚®ì€ ì˜ì–‘ì†Œ ì„­ì·¨ ë¹„ìœ¨ ë¶„ì„ì— ë”°ë¥¸ í•˜ë£¨ ê¶Œì¥ íƒ„ìˆ˜í™”ë¬¼,ë‹¨ë°±ì§ˆ,ì§€ë°©ì˜ ë¹„ìœ¨ë¡œ 5:2:3ì„ ë°”íƒ•ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.')
        see_data = st.expander('Raw dataë¥¼ ë¨¼ì € ì‚´í´ë³´ë ¤ë©´ ğŸ‘‰')
        with see_data:
            st.dataframe(con_df.drop('first_p_first',axis=1).head(500).rename(columns={'strip_first':'warmup_excercise','strip_after':'main_excercise'}))
        st.snow()
        explanation = st.expander('ì¶”ì²œ ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª…ì„ ë³´ë ¤ë©´ ğŸ‘‰')
        with explanation:
            with st.container():
                st.write("â— ë³¸ í˜ì´ì§€ëŠ” ì¤€ë¹„ ìš´ë™ 5ê°œì™€ ë³¸ ìš´ë™ ë£¨í‹´ 1ê°œì— ëŒ€í•œ ì¶”ì²œ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. \
                         ë‚˜ì´, í‚¤ ë“± ì‚¬ìš©ì ì •ë³´ì™€ ìš´ë™ ëª©í‘œì— ë”°ë¼ ì¶”ì²œ ê²°ê³¼ê°€ ë‹¬ë¼ì§‘ë‹ˆë‹¤.")
                st.write("â— ìš´ë™ ëª©í‘œ 'ì—†ìŒ'ìœ¼ë¡œ ì²´í¬í•  ì‹œì—ëŠ” ì‚¬ìš©ìì—ê²Œ ì¼ë°˜ì ì¸ ìš´ë™ ë£¨í‹´ì„ ì¶”ì²œí•©ë‹ˆë‹¤.\
                         ì¼ë°˜ì ì¸ ìš´ë™ ë£¨í‹´ ì¶”ì²œ ê²°ê³¼ëŠ” ì‚¬ìš©ì ì •ë³´ì— ê¸°ë°˜í•©ë‹ˆë‹¤.")
                st.write("â— raing(%)ì€ ì´í•©ì´ 1ì´ë©° 5ê°œì˜ ì¶”ì²œ ê²°ê³¼ì— ëŒ€í•œ ê°€ì¤‘ ì ìˆ˜ì…ë‹ˆë‹¤. \
                         ì¤‘ë³µë˜ëŠ” ì¶”ì²œ ê²°ê³¼ëŠ” ì¤‘ë³µë˜ëŠ” ë§Œí¼ ì¶”ì²œì ìˆ˜ê°€ ë†’ìŒì„ ë°˜ì˜í•©ë‹ˆë‹¤.")
                st.write("â— ë§¨ ì˜¤ë¥¸ìª½ì— ì²´í¬ë°•ìŠ¤ë¥¼ í´ë¦­í•˜ë©´ ì¶”ì²œ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ í‘œì‹œë©ë‹ˆë‹¤.\
                         ì¶”ì²œ ì„±ëŠ¥ì€ Online-testì— ì í•©í•œ ì •ë°€ë„ë¡œ ì¸¡ì •ë˜ì—ˆìœ¼ë©° ì •ë°€ë„ì— ëŒ€í•œ ì„¤ëª…ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.")
            st.divider()
            st.text_area(
                "Precision@k (ì •ë°€ë„@k)",                                                
                "Precision@këŠ” ìƒìœ„ kê°œì˜ ê²°ê³¼ ì¤‘ì—ì„œ ì‹¤ì œë¡œ ì •ë‹µì¸ ë¹„ìœ¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. "
                "ì˜ˆë¥¼ ë“¤ì–´, ìƒìœ„ 5ê°œì˜ ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ì„ ë•Œ, ì´ ì¤‘ 3ê°œê°€ ì •ë‹µì´ë¼ë©´ Precision@5ëŠ” 0.6ì…ë‹ˆë‹¤. "
                "ì¦‰, ìƒìœ„ kê°œì˜ ê²°ê³¼ ì¤‘ì— ì‹¤ì œë¡œ ì •ë‹µì¸ ê²ƒì´ ì–¼ë§ˆë‚˜ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤."
                "ë³¸ í˜ì´ì§€ì—ì„œ Precision@këŠ” ì¤€ë¹„ìš´ë™ê³¼ ë³¸ ìš´ë™ ëª¨ë‘ë¥¼ ì¸¡ì •ëŒ€ìƒìœ¼ë¡œ í–ˆìŠµë‹ˆë‹¤."
                )
            st.text_area(
                "Average Precision@k (í‰ê·  ì •ë°€ë„@k)",                                                
                "Average Precision@këŠ” ìƒìœ„ kê°œì˜ ê²°ê³¼ì— ëŒ€í•œ Precision ê°’ì„ ëª¨ë‘ êµ¬í•˜ê³ , ì´ë¥¼ ì •ë‹µì´ ìˆëŠ” ìœ„ì¹˜ë§ˆë‹¤ í‰ê· ì„ ë‚´ì–´ ê³„ì‚°í•©ë‹ˆë‹¤."                        
                "ì´ê²ƒì€ ê²€ìƒ‰ ê²°ê³¼ì˜ ìˆœì„œê°€ ì¤‘ìš”í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì •ë‹µì´ ìˆëŠ” ìœ„ì¹˜ì—ì„œì˜ Precision ê°’ë“¤ì„ í‰ê· ë‚´ì–´ ê·¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. "
                "ì´ëŠ” ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì •í™•í•œ ìˆœì„œë¡œ ê²°ê³¼ë¥¼ ì œì‹œí•˜ëŠ”ì§€ì— ëŒ€í•œ í‰ê°€ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                "ë³¸ í˜ì´ì§€ì—ì„œ Average Precision@këŠ” ìˆœì„œê°€ ì¤‘ìš”í•œ ë³¸ ìš´ë™ë§Œì„ ì¸¡ì •ëŒ€ìƒìœ¼ë¡œ í–ˆìŠµë‹ˆë‹¤."
                )
    if purpose==['ì—†ìŒ'] or purpose==[]:
        recomm_first,proba = most_similar_weight_for_None([age,height,weight,gender],con_df,5)
    else:
        recomm_first,proba = most_similar_weight([age,height,weight,gender],purpose,new_criteria,0.01,0.99,5)
    workout2 = make_warmup_df(recomm_first,proba)
    data_as_csv2= workout2.to_csv(index=False).encode("utf-8")
    st.subheader('ì¤€ë¹„ìš´ë™(Warmup) ì¶”ì²œ ê²°ê³¼', divider='red')
    st.download_button(
            label="Download Warmup Excercise as CSV",
            data=data_as_csv2,
            file_name='warmup_list.csv',
            mime='text/csv',
        )
    if "warmup" not in st.session_state:
        st.session_state.warmup=workout2
    warmup_df = st.data_editor(workout2,                            
                   column_config={
                        "select": st.column_config.CheckboxColumn(
                            "What exercise will you do?",
                            help="Select your **warmup** exercise",
                            default=False,
                        )
                    })
    all_seq = extract_seq(my_model,TOKENIZER,26,recomm_first[0])
    detailed_ex = make_main_df(all_seq,detail_workout)
    detailed_ex.rename(columns={'1ìˆœìœ„':'ìš´ë™ì´ë¦„'},inplace=True)
    # ì´ì „ì— ì„ íƒí•œ ì²´í¬ ìƒíƒœë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    data_as_csv= detailed_ex.to_csv(index=False).encode("utf-8")
    st.error('í™”ë©´ì´ ì–´ë‘ì›Œì ¸ë„, check boxë¥¼ ëˆ„ë¥´ì„¸ìš”. ì¶”ì²œ ì„±ëŠ¥ì´ í‘œì‹œë©ë‹ˆë‹¤.' ,icon='â£')
    st.subheader('ë³¸ ìš´ë™(Main) ì¶”ì²œ ê²°ê³¼', divider='red')
    st.download_button(
        label="Download Main Excercise as CSV",
        data=data_as_csv,
        file_name='excercise_list.csv',
        mime='text/csv',
    )
    if "main_ex" not in st.session_state:
        st.session_state.main_ex=detailed_ex
    m1, m2,m3= st.columns([7,1.5,1.5])
    with m1:
        main_df = st.data_editor(
                       detailed_ex,
                       column_config={
                           "select": st.column_config.CheckboxColumn(
                               "What exercise will you do?",
                               help="Select your **today`s** workout",
                               default=False,
                           )
                       },
                       disabled=["1ìˆœìœ„"],
                       hide_index=False
                   )
    if main_df['select'].any() or warmup_df['select'].any():
        precision = (len(list(main_df[main_df['select']].index))+len(list(warmup_df[warmup_df['select']].index))) / (len(main_df)+len(warmup_df))
        liked_item = main_df[main_df['select']==True]['ìš´ë™ì´ë¦„'].values.tolist()
        recomm_item = main_df['ìš´ë™ì´ë¦„'].values.tolist()
        ap = ap_at_k(liked_item,recomm_item,len(main_df))
        m2.metric(label=f'ì¶”ì²œ ì„±ëŠ¥1(Precision@{len(main_df)+len(warmup_df)})', value=np.round(precision,3))
        m3.metric(label=f"ì¶”ì²œ ì„±ëŠ¥2(Average precision@{len(main_df)})", value=np.round(ap,3))
    if long_recomm=='14ì¼':
        day = int(long_recomm[:2])
    else:
        day = int(long_recomm[0])
    long_df = longterm_routine(day,age,height,weight,gender,new_criteria,my_model,TOKENIZER,detail_workout)
    data_as_csv3= long_df.to_csv(index=False).encode("utf-8")
    st.subheader(f'{long_recomm} ìš´ë™ ë£¨í‹´ ì¶”ì²œ ê²°ê³¼', divider='red')
    st.download_button(
        label=f"Download {day}days Excercise Routine as CSV",
        data=data_as_csv3,
        file_name=f'{day}days excercise_list.csv',
        mime='text/csv',
    )
    if "long_ex" not in st.session_state:
        st.session_state.long_ex=long_df
    st.table(long_df)
    # ì…ë ¥ê°’ì´ ìˆì„ ê²½ìš° ë™ì‘
    if workout_name:
        video_url = get_url(workout_name)
        st.sidebar.write(f"URL: {video_url}")

###########Implement############
if __name__ == "__main__":
    main()
    